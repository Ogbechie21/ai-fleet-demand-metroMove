{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6de65d3",
   "metadata": {},
   "source": [
    "# Fleet Analytics & Prediction System\n",
    "\n",
    "Author: Christopher F. Ogbechie  \n",
    "Course: ANLT202  \n",
    "\n",
    "## Project Objectives\n",
    "This notebook prepares the dataset for:\n",
    "- Trip delay risk classification\n",
    "- Maintenance cost regression modeling\n",
    "\n",
    "## Dataset\n",
    "Source: Kaggle – Fleet Dataset  \n",
    "File: fleet_dummy_5000.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49836b34",
   "metadata": {},
   "source": [
    "## Classification Task\n",
    "Predict whether a trip is operationally risky or problematic.\n",
    "\n",
    "We define a trip as High Risk (1) if the status indicates a delay or problem\n",
    "(e.g., \"Delayed\", \"Cancelled\", \"Failed\"). Otherwise, it is Low Risk (0).\n",
    "\n",
    "This helps the fleet manager identify trips likely to cause service issues.\n",
    "\n",
    "## Regression Task\n",
    "Predict the maintenance_cost of a vehicle/trip based on:\n",
    "- distance_km\n",
    "- vehicle age / type\n",
    "- driving behaviour (violations, speeding incidents)\n",
    "- fuel_cost, toll_cost, load_value\n",
    "- weather_condition and route information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b99556",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44d4165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/fleet_dummy_5000.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf48285",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898b621c",
   "metadata": {},
   "source": [
    "## Define Classification Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fa0cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize status to lowercase\n",
    "df[\"status_lower\"] = df[\"status\"].str.lower()\n",
    "\n",
    "# Define high risk trips (only Delayed)\n",
    "df[\"high_risk\"] = (df[\"status_lower\"] == \"delayed\").astype(int)\n",
    "\n",
    "# Check result\n",
    "df[\"high_risk\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf8973f",
   "metadata": {},
   "source": [
    "## Define Features and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad5a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pickup_time to datetime\n",
    "df[\"pickup_time\"] = pd.to_datetime(df[\"pickup_time\"])\n",
    "\n",
    "# Add time-based features\n",
    "df[\"pickup_hour\"] = df[\"pickup_time\"].dt.hour\n",
    "df[\"pickup_dayofweek\"] = df[\"pickup_time\"].dt.dayofweek\n",
    "\n",
    "# Feature columns\n",
    "features = [\n",
    "    \"distance_km\",\n",
    "    \"fuel_cost\",\n",
    "    \"driver_pay\",\n",
    "    \"toll_cost\",\n",
    "    \"load_value\",\n",
    "    \"violation_count\",\n",
    "    \"speeding_incidents\",\n",
    "    \"gps_start_lat\",\n",
    "    \"gps_start_lon\",\n",
    "    \"gps_end_lat\",\n",
    "    \"gps_end_lon\",\n",
    "    \"pickup_hour\",\n",
    "    \"pickup_dayofweek\"\n",
    "]\n",
    "\n",
    "# Feature matrix\n",
    "X = df[features]\n",
    "\n",
    "# Targets\n",
    "y_class = df[\"high_risk\"]          # classification\n",
    "y_reg = df[\"maintenance_cost\"]     # regression\n",
    "\n",
    "X.head(), y_class.head(), y_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7affb5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"y_class shape:\", y_class.shape)\n",
    "print(\"y_reg shape:\", y_reg.shape)\n",
    "\n",
    "df[features + [\"maintenance_cost\", \"high_risk\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebeeaa1",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd228a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classification split\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
    ")\n",
    "\n",
    "# Regression split\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Classification Train:\", X_train_c.shape, \"Test:\", X_test_c.shape)\n",
    "print(\"Regression Train:\", X_train_r.shape, \"Test:\", X_test_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd633ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X.columns.tolist()\n",
    "numeric_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e4ea56",
   "metadata": {},
   "source": [
    "## Scaling & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83a4e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Preprocessing pipeline for numeric features\n",
    "preprocess_numeric = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498422e",
   "metadata": {},
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2070de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Classification pipeline\n",
    "clf_logreg = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LogisticRegression(max_iter=1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train\n",
    "clf_logreg.fit(X_train_c, y_train_c)\n",
    "\n",
    "# Predict\n",
    "y_pred_logreg = clf_logreg.predict(X_test_c)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Logistic Regression Results:\\n\")\n",
    "print(classification_report(y_test_c, y_pred_logreg))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_c, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14be17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest classification pipeline\n",
    "clf_rf = Pipeline(\n",
    "    steps=[\n",
    "        # Tree models don't strictly need scaling, so we skip StandardScaler here\n",
    "        (\"model\", RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "clf_rf.fit(X_train_c, y_train_c)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = clf_rf.predict(X_test_c)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=== Random Forest Results ===\\n\")\n",
    "print(classification_report(y_test_c, y_pred_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_c, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f7f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logreg_bal = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf_logreg_bal.fit(X_train_c, y_train_c)\n",
    "\n",
    "y_pred_logreg_bal = clf_logreg_bal.predict(X_test_c)\n",
    "\n",
    "print(\"=== Balanced Logistic Regression Results ===\\n\")\n",
    "print(classification_report(y_test_c, y_pred_logreg_bal))\n",
    "print(confusion_matrix(y_test_c, y_pred_logreg_bal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e2dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf_bal = Pipeline(\n",
    "    steps=[\n",
    "        (\"model\", RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced\"\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf_rf_bal.fit(X_train_c, y_train_c)\n",
    "\n",
    "y_pred_rf_bal = clf_rf_bal.predict(X_test_c)\n",
    "\n",
    "print(\"=== Balanced Random Forest Results ===\\n\")\n",
    "print(classification_report(y_test_c, y_pred_rf_bal))\n",
    "print(confusion_matrix(y_test_c, y_pred_rf_bal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80257e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Linear Regression pipeline\n",
    "reg_lin = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "# Train\n",
    "reg_lin.fit(X_train_r, y_train_r)\n",
    "\n",
    "# Predict\n",
    "y_pred_lin = reg_lin.predict(X_test_r)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test_r, y_pred_lin)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_r, y_pred_lin))\n",
    "r2 = r2_score(y_test_r, y_pred_lin)\n",
    "\n",
    "print(\"=== Linear Regression Results ===\")\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e885a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "reg_rf = Pipeline([\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "reg_rf.fit(X_train_r, y_train_r)\n",
    "y_pred_rf = reg_rf.predict(X_test_r)\n",
    "\n",
    "mae_rf = mean_absolute_error(y_test_r, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test_r, y_pred_rf))\n",
    "r2_rf = r2_score(y_test_r, y_pred_rf)\n",
    "\n",
    "print(\"=== Random Forest Regressor Results ===\")\n",
    "print(\"MAE:\", mae_rf)\n",
    "print(\"RMSE:\", rmse_rf)\n",
    "print(\"R²:\", r2_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_feature_cols = [\n",
    "    \"distance_km\",\n",
    "    \"fuel_cost\",\n",
    "    \"driver_pay\",\n",
    "    \"toll_cost\",\n",
    "    \"load_value\",\n",
    "    \"violation_count\",\n",
    "    \"speeding_incidents\",\n",
    "    \"gps_start_lat\",\n",
    "    \"gps_start_lon\",\n",
    "    \"gps_end_lat\",\n",
    "    \"gps_end_lon\",\n",
    "    \"pickup_hour\",\n",
    "    \"pickup_dayofweek\"\n",
    "]\n",
    "\n",
    "# Rebuild regression feature matrix\n",
    "X_reg = df[reg_feature_cols]\n",
    "\n",
    "# Split again\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(X_reg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dcc1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lin = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "reg_lin.fit(X_train_r, y_train_r)\n",
    "\n",
    "y_pred_lin = reg_lin.predict(X_test_r)\n",
    "\n",
    "mae = mean_absolute_error(y_test_r, y_pred_lin)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_r, y_pred_lin))\n",
    "r2 = r2_score(y_test_r, y_pred_lin)\n",
    "\n",
    "print(\"=== Fixed Linear Regression Results ===\")\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4848be",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_rf = Pipeline([\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "reg_rf.fit(X_train_r, y_train_r)\n",
    "\n",
    "y_pred_rf = reg_rf.predict(X_test_r)\n",
    "\n",
    "mae_rf = mean_absolute_error(y_test_r, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test_r, y_pred_rf))\n",
    "r2_rf = r2_score(y_test_r, y_pred_rf)\n",
    "\n",
    "print(\"=== Fixed Random Forest Results ===\")\n",
    "print(\"MAE:\", mae_rf)\n",
    "print(\"RMSE:\", rmse_rf)\n",
    "print(\"R²:\", r2_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2824b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_logreg = {\n",
    "    \"model__C\": [0.01, 0.1, 1, 10],\n",
    "    \"model__solver\": [\"lbfgs\", \"liblinear\"]\n",
    "}\n",
    "\n",
    "grid_logreg = GridSearchCV(\n",
    "    clf_logreg_bal,    # use your working balanced classifier\n",
    "    param_grid_logreg,\n",
    "    scoring=\"recall\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_logreg.fit(X_train_c, y_train_c)\n",
    "\n",
    "print(\"Best Logistic Regression Parameters:\", grid_logreg.best_params_)\n",
    "print(\"Best Cross-Validated Recall:\", grid_logreg.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5687163",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    \"model__n_estimators\": [50, 100, 200],\n",
    "    \"model__max_depth\": [None, 10, 20],\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    reg_rf,\n",
    "    param_grid_rf,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train_r, y_train_r)\n",
    "\n",
    "print(\"Best Random Forest Parameters:\", grid_rf.best_params_)\n",
    "print(\"Best CV MAE:\", -grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale data (DL models need scaled input)\n",
    "scaler_dl = StandardScaler()\n",
    "X_train_dl = scaler_dl.fit_transform(X_train_c)\n",
    "X_test_dl = scaler_dl.transform(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe50ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation=\"relu\", input_shape=(X_train_dl.shape[1],)))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd55b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train_dl, y_train_c,\n",
    "    validation_data=(X_test_dl, y_test_c),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c6b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dl = (model.predict(X_test_dl) > 0.5).astype(int).flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"=== Deep Learning Classification Results ===\")\n",
    "print(classification_report(y_test_c, y_pred_dl))\n",
    "print(confusion_matrix(y_test_c, y_pred_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94034a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Compute class weights for 0 and 1\n",
    "classes = np.unique(y_train_c)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=y_train_c\n",
    ")\n",
    "\n",
    "class_weight_dict = {int(c): w for c, w in zip(classes, class_weights)}\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d3fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train_dl, y_train_c,\n",
    "    validation_data=(X_test_dl, y_test_c),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b6b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Train:\", X_train_c.shape, \"Test:\", X_test_c.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
